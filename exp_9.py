# -*- coding: utf-8 -*-
"""exp 9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-vDyQHSIDnz_yav9WzDsLuEQt53UR_8K
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# -----------------------------------------
# 1. Generate Non-Linear Sample Data
# -----------------------------------------

np.random.seed(0)
X = np.linspace(-5, 5, 50).reshape(-1, 1)
y = 0.5 * X**2 + X + 2 + np.random.randn(50, 1)*2  # Quadratic data

# -----------------------------------------
# 2. Linear Regression
# -----------------------------------------

linear_model = LinearRegression()
linear_model.fit(X, y)
y_pred_linear = linear_model.predict(X)

# -----------------------------------------
# 3. Polynomial Regression (Degree 2)
# -----------------------------------------

poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)

poly_model = LinearRegression()
poly_model.fit(X_poly, y)
y_pred_poly = poly_model.predict(X_poly)

# -----------------------------------------
# 4. Evaluation
# -----------------------------------------

mse_linear = mean_squared_error(y, y_pred_linear)
r2_linear = r2_score(y, y_pred_linear)

mse_poly = mean_squared_error(y, y_pred_poly)
r2_poly = r2_score(y, y_pred_poly)

print("Linear Regression")
print("MSE:", mse_linear)
print("R2 Score:", r2_linear)

print("\nPolynomial Regression (Degree 2)")
print("MSE:", mse_poly)
print("R2 Score:", r2_poly)

# -----------------------------------------
# 5. Plot Results
# -----------------------------------------

plt.scatter(X, y, color='black', label="Actual Data")

plt.plot(X, y_pred_linear, color='blue', label="Linear Regression")
plt.plot(X, y_pred_poly, color='red', label="Polynomial Regression (Degree 2)")

plt.xlabel("X")
plt.ylabel("Y")
plt.legend()
plt.title("Linear vs Polynomial Regression")
plt.show()